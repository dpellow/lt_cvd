{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv \n",
    "from sksurv.metrics import concordance_index_censored, brier_score, cumulative_dynamic_auc\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress specific UserWarning from sklearn.utils.validation\n",
    "warnings.filterwarnings(\"ignore\", message=\"X has feature names, but KBinsDiscretizer was fitted without feature names\", module=\"sklearn.utils.validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE PATHS\n",
    "# CHANGE THESE TO MATCH YOUR DIRECTORY STRUCTURE\n",
    "\n",
    "model_path = './' # where the rsf.pkl, norm.pkl and training_distr.csv files are located\n",
    "cohort_file = './prediction_cohort.csv' # this is output by the preprocessing script\n",
    "outdir = './results/' # where to put the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing and loading function definitions\n",
    "def load_model(model_path):\n",
    "    print(\"Loading model\")\n",
    "    rsffile = os.path.join(model_path, 'rsf.pkl')\n",
    "    with open(rsffile, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    bins_file = os.path.join(model_path, 'norm.pkl')\n",
    "    with open(bins_file, 'rb') as f:\n",
    "        bins = pickle.load(f)\n",
    "    \n",
    "    explainer_file = os.path.join(model_path, 'explainer.pkl') \n",
    "    with open(explainer_file, \"rb\") as f:\n",
    "        explainer = pickle.load(f)\n",
    "    \n",
    "    # needed to compute brier score\n",
    "    training_distr = pd.read_csv(os.path.join(model_path, 'training_distr.csv'), index_col=0)\n",
    "        \n",
    "    return model, bins, training_distr, explainer\n",
    "\n",
    "def preprocess(df):\n",
    "    # add any columns that are missing (they will be imputed as missing values - warn)\n",
    "    cols = ['ID', 'AGE_AT_TX', 'CURR_AGE', 'YRS_SINCE_TRANS',\n",
    "            'SEX', 'SMOKER', 'DM', 'HTN', 'LIP', 'CV_HISTORY', 'ANTI_PLATELET',\n",
    "            'ANTI_HTN', 'STATIN', 'BMI', 'CANCER', 'METAB', 'ALD',\n",
    "            'HEP', 'FULM', 'IMMUNE', 'RE_TX', \"CYCLOSPORINE_TROUGH_LEVEL\",\n",
    "            \"TACROLIMUS_TROUGH_LEVEL\", \"ALP\", \"ALT\", \"AST\", \"SERUM_CREATININE\",\n",
    "            \"EVENT\", \"MONTHS_TO_EVENT\"]\n",
    "    imp_cols = [\"BMI\",\"CYCLOSPORINE_TROUGH_LEVEL\", \"TACROLIMUS_TROUGH_LEVEL\",\n",
    "                \"ALP\", \"ALT\", \"AST\", \"SERUM_CREATININE\"]\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            if c in imp_cols:\n",
    "                print(f\"Warning: {c} not in dataframe - will be imputed as a constant for all patients\")\n",
    "                df[c] = 24 # 50 bins\n",
    "            else:\n",
    "                print(f\"Error: Feature {c} required. Update the cohort file to include this feature\")\n",
    "                raise ValueError(f\"Column {c} not in dataframe\")\n",
    "    \n",
    "    # check patient ages and drop those underage at tx\n",
    "    # drop any less than 1 year post tx\n",
    "    # print out ids of all dropped patients\n",
    "    if len(df[df['AGE_AT_TX'] < 18]) > 0:\n",
    "        print(\"Patients must be >18 years at transplant to be included. Dropping:\")\n",
    "        print(df[df['AGE_AT_TX'] < 18]['ID'].values.tolist())\n",
    "    if len(df[df[\"YRS_SINCE_TRANS\"] < 1]) > 0:\n",
    "        print(\"Patients must be >1 year post transplant to be included. Dropping:\")\n",
    "        print(df[df[\"YRS_SINCE_TRANS\"] < 1]['ID'].values.tolist())\n",
    "    df = df[df['AGE_AT_TX'] >= 18]\n",
    "    df = df[df['YRS_SINCE_TRANS'] >= 1]\n",
    "    \n",
    "    # re-order the columns, and keep only the ones that are needed\n",
    "    df = df[cols]\n",
    "    \n",
    "    # preprocess tac/cyclo levels as follows:\n",
    "    # if tac is not nan or 0, set cyclo to 0\n",
    "    # if cyclo is not nan or 0, set tac to 0\n",
    "    # if cyclo is nan set to 0\n",
    "    df[\"CYCLOSPORINE_TROUGH_LEVEL\"] = df[\"CYCLOSPORINE_TROUGH_LEVEL\"].fillna(0)\n",
    "    df.loc[((df[\"TACROLIMUS_TROUGH_LEVEL\"].notna()) & (df[\"TACROLIMUS_TROUGH_LEVEL\"]>0)),\n",
    "                    \"CYCLOSPORINE_TROUGH_LEVEL\"] = 0\n",
    "    df.loc[((df[\"CYCLOSPORINE_TROUGH_LEVEL\"].notna()) & (df[\"CYCLOSPORINE_TROUGH_LEVEL\"]>0)),\n",
    "                    \"TACROLIMUS_TROUGH_LEVEL\"] = 0\n",
    "    \n",
    "    # constant imputation of nan to 24 (median bin) in the impute columns\n",
    "    \n",
    "    df[imp_cols] = df[imp_cols].fillna(24)\n",
    "    \n",
    "    # if any nans in the other columns - drop the row and warn\n",
    "    if df[[c for c in cols if c in cols and c not in imp_cols]].isna().any().any():\n",
    "        print(\"Dropping the following patients that have missing values in required columns:\")\n",
    "        print(df[df[[c for c in cols if c in cols and c not in imp_cols]].isna().any(axis=1)]['ID'].values.tolist())\n",
    "    df = df.dropna(subset=[c for c in cols if c not in imp_cols])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def run_binning(df, bins):\n",
    "    norm_cols = [\"AGE_AT_TX\",\"ALP\", \"ALT\", \"AST\", \"BMI\", \"CURR_AGE\", \"CYCLOSPORINE_TROUGH_LEVEL\", \n",
    "                 \"SERUM_CREATININE\", \"TACROLIMUS_TROUGH_LEVEL\", \"YRS_SINCE_TRANS\"]\n",
    "    for col in norm_cols:\n",
    "        transformed_values = np.full(df[col].shape, -1) # nan value is -1\n",
    "        non_nan_mask = ~(df[col]==-1)  # Mask for non-NaN values\n",
    "        transformed_values[non_nan_mask] = bins[col].transform(df.loc[non_nan_mask, [col]])[:, 0]\n",
    "        df[col] = transformed_values\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_subjects(cohort_path, bins):\n",
    "    print(\"Loading cohort\")\n",
    "    df = pd.read_csv(cohort_path)\n",
    "    \n",
    "    # preprocess the dataframe\n",
    "    df = preprocess(df)\n",
    "    \n",
    "    df = run_binning(df,bins)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model running function definition\n",
    "def run_predictions(df, rsf):\n",
    "    print(\"Running predictions\")\n",
    "    chfs = rsf.predict_survival_function(df.drop(columns=['ID','EVENT','MONTHS_TO_EVENT']))\n",
    "    ten_yr_risk = 1 - np.array([f([120]) for f in chfs])\n",
    "    preds = pd.DataFrame(ten_yr_risk, columns=['10 year risk'],index=df['ID'])\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance metric function definitions\n",
    "def make_structured_array(event, time):\n",
    "    return np.array([(bool(e), t) for e, t in zip(event, time)],\n",
    "                    dtype=[('event', 'bool'), ('time', 'f8')])\n",
    "    \n",
    "def compute_binwise_km_calibration(data, preds, t_eval=120):\n",
    "    bins = [0.0, 0.075, 0.20, 1.0]\n",
    "    labels = ['<7.5%', '7.5-20%', '>20%']\n",
    "    data = data.copy()\n",
    "    # data['predicted_event_prob'] = preds[\"10 year risk\"]\n",
    "    data = pd.merge(data, preds, on=\"ID\", how=\"left\")  ## updated 2025-09-12\n",
    "    data = data.rename(columns={ \n",
    "        \"10 year risk\": \"predicted_event_prob\"\n",
    "    })\n",
    "    # data['bin'] = pd.cut(preds[\"10 year risk\"], bins=bins, labels=labels, include_lowest=True)\n",
    "    bin_data = pd.cut(preds.squeeze(), bins=bins, labels=labels, include_lowest=True) ## updated 2025-09-12\n",
    "    data = pd.merge(data, bin_data, on=\"ID\", how=\"left\")  ## updated 2025-09-12\n",
    "    data = data.rename(columns={\n",
    "        \"10 year risk\": \"bin\"\n",
    "    })\n",
    "    results = []\n",
    "    for label in labels:\n",
    "        bin_df = data[data['bin'] == label]\n",
    "\n",
    "        surv_data = make_structured_array(bin_df['EVENT'], bin_df['MONTHS_TO_EVENT'])\n",
    "        \n",
    "        kmf = KaplanMeierFitter()\n",
    "        kmf.fit(surv_data['time'], event_observed=surv_data['event'])\n",
    "        km_surv = kmf.survival_function_at_times(t_eval).values[0]\n",
    "        km_event_rate = 1 - km_surv\n",
    "        \n",
    "        pred_mean = bin_df['predicted_event_prob'].mean()\n",
    "        abs_error = abs(pred_mean - km_event_rate)\n",
    "\n",
    "        results.append({\n",
    "            'bin': label,\n",
    "            'n': len(bin_df),\n",
    "            'mean_pred': pred_mean,\n",
    "            'km_event_rate': km_event_rate,\n",
    "            'abs_error': abs_error\n",
    "        })\n",
    "    results = pd.DataFrame(results)\n",
    "    weights = results['n'] / results['n'].sum()\n",
    "    weighted_avg = (results['abs_error'] * weights).sum()\n",
    "    print(results)\n",
    "    return weighted_avg, results\n",
    "\n",
    "\n",
    "def run_evaluations(preds, df, training_brier_distr):\n",
    "    print(\"Evaluating predictions\")\n",
    "    yt = Surv.from_arrays(df['EVENT'], df['MONTHS_TO_EVENT'])\n",
    "    y = Surv.from_arrays(training_brier_distr['EVENT'], training_brier_distr['MONTHS_TO_EVENT'])\n",
    "    c_ind = concordance_index_censored(df['EVENT'].astype(bool), df['MONTHS_TO_EVENT'], preds['10 year risk'])[0]\n",
    "    _, brier = brier_score(y, yt, 1-preds['10 year risk'], 120)\n",
    "    auc, _ = cumulative_dynamic_auc(y, yt, preds['10 year risk'], [120])\n",
    "    avg_calib, binned_results = compute_binwise_km_calibration(df, preds['10 year risk'], t_eval=120)\n",
    "    print(f\"Concordance index: {c_ind.round(3)}\")\n",
    "    print(f\"Brier score: {brier.round(3)}\")\n",
    "    print(f\"CD-AUC: {auc[0].round(3)}\")\n",
    "    print(\"Average absolute calibration error (binwise KM): \", avg_calib.round(4))\n",
    "    return c_ind.round(4), brier.round(4), auc[0].round(4), avg_calib.round(4), binned_results\n",
    "\n",
    "\n",
    "def save_results(preds, c_ind, brier, cd_auc, wm_sae, binned_results, outdir):\n",
    "    print(\"Saving results\")\n",
    "    preds.to_csv(os.path.join(outdir, 'predictions.csv'))\n",
    "    binned_results.to_csv(os.path.join(outdir, 'binned_calibration.csv'))\n",
    "    with open(os.path.join(outdir, 'metrics.txt'), 'w') as f:\n",
    "        f.write(f\"Concordance index: {c_ind}\\n\")\n",
    "        f.write(f\"Brier score: {brier}\\n\")\n",
    "        f.write(f\"CD-AUC: {cd_auc}\\n\")\n",
    "        f.write(f\"wm-SAE: {wm_sae}\\n\")\n",
    "    print(\"Results saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for running shap\n",
    "\n",
    "class RSFPredictWrapper:\n",
    "    \"\"\"Callable wrapper around an RSF model to make it picklable.\"\"\"\n",
    "    def __init__(self, rsf, t_eval):\n",
    "        self.rsf = rsf\n",
    "        self.t_eval = t_eval\n",
    "\n",
    "    def __call__(self, X):\n",
    "        surv_fns = self.rsf.predict_survival_function(X)\n",
    "        risk_scores = np.array([1 - fn(self.t_eval[0]) for fn in surv_fns])\n",
    "        return risk_scores\n",
    "\n",
    "def run_shap(df, explainer, outdir):\n",
    "    X_test = df.drop(columns=['ID','EVENT','MONTHS_TO_EVENT'])\n",
    "    print(\"Running SHAP analysis\")\n",
    "    shap_values = explainer(X_test)\n",
    "    \n",
    "    shap.summary_plot(shap_values, X_test, feature_names=X_test.columns, show=False,\n",
    "                      max_display=15, plot_size=[12,10])\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.savefig(os.path.join(outdir, 'shap_summary_plot.png'),dpi=400)\n",
    "    plt.close()\n",
    "    \n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE CODE\n",
    "\n",
    "rsf, bins, training_distr, explainer = load_model(model_path)\n",
    "\n",
    "df = get_subjects(cohort_file,bins)\n",
    "\n",
    "preds = run_predictions(df,rsf)\n",
    "\n",
    "shap = run_shap(df,explainer, outdir)\n",
    "\n",
    "c_ind, brier, cd_auc, wm_sae, binned_results   = run_evaluations(preds, df, training_distr)\n",
    "\n",
    "save_results(preds, c_ind, brier, cd_auc, wm_sae, binned_results, outdir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
